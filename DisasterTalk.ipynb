{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import pipeline, AutoTokenizer, BertForSequenceClassification, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "bert_id = \"/home/erik/PycharmProjects/Kaggle/Models\"\n",
    "bert_id_1 = \"bert-base-cased\"\n",
    "device = 'cuda'\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_id_1)\n",
    "model = BertForSequenceClassification.from_pretrained(bert_id, num_labels=2)\n",
    "pipe = pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class SentimentPolarityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class SentimentPolarityDatasetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def fetch_datasets():\n",
    "    \"\"\"\n",
    "    Fetches data from the /Data directory. Parses labels, tokenizes inputs. Loads data into a custom pytorch Dataset\n",
    "        Returns:\n",
    "            Six SentimentPolarityDataset datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    with open('Data/nlp-getting-started/train.csv') as polarity_data:\n",
    "        polarity_array = pd.read_csv(polarity_data)\n",
    "        train_texts = polarity_array['text'].values.tolist()\n",
    "        train_labels = polarity_array['target'].values.tolist()\n",
    "        type(train_texts)\n",
    "\n",
    "    with open('Data/nlp-getting-started/test.csv') as polarity_data:\n",
    "        polarity_array = pd.read_csv(polarity_data)\n",
    "        test_texts = polarity_array['text'].values.tolist()\n",
    "\n",
    "    tokenizer_deberta = AutoTokenizer.from_pretrained(bert_id_1)\n",
    "\n",
    "    encodings = tokenizer_deberta(train_texts, truncation=True, padding=True,add_special_tokens=True,)\n",
    "    train_dataset = SentimentPolarityDataset(encodings, train_labels)\n",
    "    encodings_test = tokenizer_deberta(test_texts, truncation=True, padding=True,       add_special_tokens=True,\n",
    "      return_token_type_ids=False,\n",
    "      pad_to_max_length=True,\n",
    "      return_attention_mask=True,\n",
    "      return_tensors='pt')\n",
    "    test_dataset = SentimentPolarityDatasetTest(encodings_test)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def tune(model, optim, dataset, epochs=15):\n",
    "    \"\"\"\n",
    "    Trains a given model on the given dataset using the given optimizer.\n",
    "        Parameters:\n",
    "            model (pytorch model): The model we want to train.\n",
    "            optim (pytoch optimizer): The optimizer we wish to use.\n",
    "            dataset (pytorch dataset): The dataset we wish to tune our model to.\n",
    "    \"\"\"\n",
    "    print(len(dataset))\n",
    "    loader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    i = 0\n",
    "    for epoch in range(epochs):\n",
    "        for batch in tqdm(loader):\n",
    "            i += 1\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            avg_loss += loss.item()\n",
    "            optim.step()\n",
    "        print(\"Training loss:\",avg_loss/i)\n",
    "    model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2284: UserWarning: Though `pad_to_max_length` = `True`, it is ignored because `padding`=`True`.\n",
      "  warnings.warn(\"Though `pad_to_max_length` = `True`, it is ignored because `padding`=`True`.\")\n",
      "/home/erik/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03703165094566047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.04060422151356959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03929158923468907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03661188566325529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03515249320169597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0339925576297287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03368169449377714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:56<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03243399187568921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:59<00:00,  8.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03200277332189599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:59<00:00,  8.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.03164365300785177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.030831690099735652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.030342237780407705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:01<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.030208566513572482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:59<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02937893694615213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0290130530768476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = fetch_datasets()\n",
    "\n",
    "model_ = pipe.model\n",
    "model_.to(device)\n",
    "optim = AdamW(model_.parameters(), lr=1e-5)\n",
    "tune(model_, optim, train)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "with open('Data/nlp-getting-started/test.csv') as polarity_data:\n",
    "    polarity_array = pd.read_csv(polarity_data)\n",
    "    test_texts = polarity_array['text'].values.tolist()\n",
    "def predict(model, dataset):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    i = 0\n",
    "    for batch in tqdm(dataset):\n",
    "        encoded_review = tokenizer.encode_plus(\n",
    "            batch,\n",
    "            add_special_tokens=True,\n",
    "            return_token_type_ids=False,\n",
    "            truncation=True, padding=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            )\n",
    "        input_ids = encoded_review['input_ids'].to(device)\n",
    "        attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "        output = model(input_ids, attention_mask)\n",
    "        _, prediction = torch.max(output[0], dim=1)\n",
    "        preds.append((polarity_array['id'].values.tolist()[i] ,int(prediction)))\n",
    "        i += 1\n",
    "    return preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [00:21<00:00, 148.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0, 1),\n (2, 1),\n (3, 1),\n (9, 1),\n (11, 1),\n (12, 1),\n (21, 0),\n (22, 0),\n (27, 0),\n (29, 0),\n (30, 0),\n (35, 0),\n (42, 0),\n (43, 0),\n (45, 0),\n (46, 1),\n (47, 0),\n (51, 1),\n (58, 0),\n (60, 0),\n (69, 0),\n (70, 0),\n (72, 0),\n (75, 1),\n (84, 0),\n (87, 0),\n (88, 0),\n (90, 0),\n (94, 0),\n (99, 1),\n (101, 0),\n (103, 0),\n (106, 1),\n (108, 0),\n (111, 1),\n (115, 0),\n (116, 1),\n (122, 0),\n (123, 0),\n (124, 1),\n (125, 0),\n (127, 1),\n (140, 0),\n (142, 1),\n (147, 0),\n (148, 0),\n (150, 0),\n (152, 0),\n (154, 1),\n (155, 0),\n (166, 0),\n (167, 0),\n (169, 1),\n (177, 0),\n (179, 0),\n (181, 0),\n (186, 0),\n (188, 0),\n (189, 0),\n (192, 0),\n (200, 1),\n (202, 0),\n (206, 1),\n (207, 1),\n (214, 1),\n (217, 1),\n (223, 0),\n (224, 1),\n (227, 1),\n (228, 1),\n (230, 0),\n (233, 1),\n (234, 1),\n (236, 1),\n (239, 1),\n (250, 1),\n (255, 0),\n (257, 0),\n (259, 1),\n (275, 1),\n (278, 0),\n (282, 0),\n (284, 0),\n (286, 1),\n (288, 1),\n (292, 0),\n (295, 0),\n (300, 0),\n (304, 1),\n (305, 1),\n (306, 1),\n (308, 0),\n (311, 0),\n (317, 0),\n (319, 0),\n (323, 0),\n (324, 0),\n (325, 0),\n (326, 1),\n (333, 0),\n (339, 0),\n (342, 0),\n (343, 1),\n (350, 0),\n (351, 0),\n (357, 0),\n (359, 0),\n (362, 0),\n (366, 1),\n (367, 0),\n (369, 0),\n (373, 0),\n (374, 1),\n (376, 0),\n (377, 0),\n (378, 0),\n (379, 1),\n (382, 0),\n (385, 0),\n (387, 1),\n (388, 0),\n (391, 0),\n (392, 0),\n (395, 0),\n (399, 0),\n (400, 0),\n (403, 0),\n (405, 0),\n (408, 0),\n (411, 1),\n (414, 0),\n (416, 0),\n (417, 0),\n (422, 0),\n (425, 0),\n (428, 0),\n (430, 1),\n (431, 0),\n (433, 0),\n (434, 0),\n (439, 0),\n (441, 0),\n (449, 0),\n (458, 0),\n (460, 0),\n (464, 0),\n (473, 1),\n (488, 0),\n (491, 0),\n (494, 1),\n (497, 0),\n (500, 1),\n (505, 0),\n (507, 0),\n (508, 0),\n (510, 0),\n (511, 0),\n (515, 1),\n (525, 0),\n (529, 0),\n (532, 0),\n (534, 0),\n (537, 1),\n (539, 0),\n (541, 0),\n (545, 0),\n (547, 1),\n (548, 1),\n (549, 1),\n (553, 1),\n (554, 0),\n (555, 1),\n (557, 0),\n (562, 0),\n (566, 1),\n (572, 1),\n (573, 1),\n (582, 1),\n (586, 1),\n (587, 0),\n (590, 1),\n (591, 0),\n (593, 0),\n (595, 0),\n (596, 1),\n (597, 0),\n (601, 0),\n (602, 0),\n (605, 1),\n (610, 1),\n (616, 0),\n (618, 1),\n (620, 1),\n (626, 0),\n (627, 0),\n (629, 0),\n (632, 1),\n (634, 0),\n (639, 0),\n (645, 1),\n (647, 1),\n (648, 0),\n (650, 1),\n (663, 0),\n (666, 1),\n (668, 0),\n (670, 0),\n (673, 1),\n (676, 0),\n (678, 0),\n (692, 0),\n (693, 1),\n (694, 0),\n (695, 0),\n (696, 1),\n (698, 1),\n (701, 1),\n (703, 1),\n (707, 1),\n (708, 1),\n (711, 1),\n (715, 1),\n (718, 0),\n (722, 0),\n (723, 0),\n (733, 1),\n (741, 0),\n (742, 1),\n (743, 1),\n (747, 0),\n (749, 0),\n (750, 0),\n (756, 0),\n (757, 0),\n (760, 0),\n (764, 0),\n (765, 0),\n (766, 0),\n (768, 1),\n (769, 0),\n (771, 0),\n (772, 0),\n (776, 0),\n (778, 0),\n (780, 0),\n (785, 1),\n (789, 0),\n (792, 0),\n (793, 0),\n (811, 1),\n (813, 0),\n (816, 0),\n (821, 0),\n (824, 0),\n (825, 0),\n (827, 0),\n (830, 1),\n (831, 1),\n (839, 0),\n (844, 0),\n (847, 0),\n (850, 0),\n (854, 1),\n (855, 1),\n (858, 0),\n (861, 0),\n (862, 0),\n (865, 1),\n (869, 0),\n (879, 1),\n (880, 1),\n (887, 1),\n (889, 1),\n (897, 0),\n (900, 1),\n (901, 0),\n (904, 1),\n (908, 0),\n (909, 0),\n (910, 1),\n (913, 1),\n (914, 1),\n (917, 1),\n (918, 1),\n (920, 0),\n (922, 0),\n (924, 0),\n (925, 0),\n (927, 0),\n (933, 0),\n (937, 0),\n (943, 0),\n (949, 0),\n (950, 1),\n (954, 0),\n (966, 0),\n (967, 0),\n (969, 0),\n (970, 1),\n (973, 0),\n (975, 0),\n (980, 0),\n (988, 0),\n (989, 0),\n (995, 0),\n (1000, 0),\n (1003, 0),\n (1007, 0),\n (1011, 0),\n (1012, 0),\n (1013, 1),\n (1014, 0),\n (1016, 1),\n (1019, 0),\n (1025, 0),\n (1027, 0),\n (1028, 1),\n (1030, 0),\n (1033, 1),\n (1034, 1),\n (1039, 0),\n (1046, 0),\n (1047, 0),\n (1053, 0),\n (1055, 0),\n (1056, 0),\n (1059, 1),\n (1060, 0),\n (1063, 0),\n (1064, 0),\n (1068, 0),\n (1076, 0),\n (1086, 0),\n (1087, 0),\n (1089, 0),\n (1092, 0),\n (1095, 0),\n (1096, 0),\n (1097, 0),\n (1100, 0),\n (1101, 0),\n (1107, 0),\n (1108, 0),\n (1111, 0),\n (1115, 1),\n (1116, 1),\n (1121, 0),\n (1125, 0),\n (1127, 0),\n (1131, 0),\n (1133, 0),\n (1135, 0),\n (1137, 0),\n (1140, 0),\n (1144, 0),\n (1147, 1),\n (1148, 0),\n (1150, 0),\n (1158, 0),\n (1159, 0),\n (1161, 0),\n (1163, 0),\n (1165, 0),\n (1169, 0),\n (1171, 1),\n (1172, 0),\n (1176, 0),\n (1180, 0),\n (1184, 0),\n (1186, 0),\n (1187, 0),\n (1192, 0),\n (1193, 0),\n (1194, 0),\n (1197, 0),\n (1200, 0),\n (1205, 0),\n (1210, 0),\n (1216, 0),\n (1220, 0),\n (1231, 0),\n (1233, 0),\n (1246, 0),\n (1247, 0),\n (1248, 0),\n (1255, 0),\n (1256, 0),\n (1257, 0),\n (1258, 0),\n (1260, 0),\n (1261, 0),\n (1265, 0),\n (1266, 0),\n (1268, 0),\n (1274, 0),\n (1281, 0),\n (1285, 0),\n (1286, 0),\n (1291, 0),\n (1292, 0),\n (1295, 0),\n (1299, 0),\n (1306, 0),\n (1310, 0),\n (1311, 0),\n (1313, 0),\n (1314, 0),\n (1322, 0),\n (1323, 0),\n (1325, 0),\n (1329, 0),\n (1330, 0),\n (1333, 0),\n (1336, 0),\n (1339, 0),\n (1342, 0),\n (1344, 0),\n (1355, 1),\n (1357, 0),\n (1358, 0),\n (1359, 0),\n (1364, 0),\n (1366, 0),\n (1367, 0),\n (1370, 1),\n (1373, 0),\n (1377, 0),\n (1386, 0),\n (1387, 0),\n (1392, 0),\n (1397, 0),\n (1398, 0),\n (1400, 0),\n (1403, 0),\n (1404, 0),\n (1410, 0),\n (1413, 1),\n (1416, 0),\n (1417, 0),\n (1423, 0),\n (1424, 1),\n (1426, 0),\n (1427, 0),\n (1428, 0),\n (1430, 0),\n (1434, 0),\n (1435, 0),\n (1437, 0),\n (1438, 0),\n (1442, 0),\n (1446, 0),\n (1451, 0),\n (1457, 0),\n (1461, 0),\n (1462, 0),\n (1465, 0),\n (1468, 0),\n (1469, 0),\n (1471, 0),\n (1476, 1),\n (1478, 0),\n (1481, 0),\n (1489, 0),\n (1490, 0),\n (1492, 0),\n (1496, 0),\n (1512, 0),\n (1516, 0),\n (1517, 0),\n (1528, 0),\n (1529, 1),\n (1536, 1),\n (1539, 0),\n (1541, 0),\n (1542, 0),\n (1548, 1),\n (1550, 1),\n (1551, 1),\n (1552, 1),\n (1557, 1),\n (1563, 1),\n (1564, 0),\n (1565, 0),\n (1566, 1),\n (1571, 0),\n (1578, 0),\n (1581, 0),\n (1583, 0),\n (1584, 0),\n (1586, 1),\n (1589, 1),\n (1592, 1),\n (1598, 1),\n (1606, 1),\n (1612, 0),\n (1616, 1),\n (1620, 0),\n (1624, 0),\n (1629, 1),\n (1630, 1),\n (1635, 1),\n (1640, 1),\n (1641, 1),\n (1642, 1),\n (1651, 1),\n (1655, 1),\n (1656, 1),\n (1659, 1),\n (1664, 1),\n (1667, 1),\n (1668, 1),\n (1674, 1),\n (1678, 0),\n (1680, 1),\n (1681, 1),\n (1682, 1),\n (1685, 1),\n (1695, 1),\n (1696, 1),\n (1697, 0),\n (1704, 1),\n (1708, 0),\n (1711, 1),\n (1713, 1),\n (1714, 0),\n (1717, 1),\n (1729, 0),\n (1730, 0),\n (1732, 0),\n (1734, 1),\n (1736, 1),\n (1738, 0),\n (1742, 0),\n (1743, 1),\n (1746, 0),\n (1748, 1),\n (1749, 0),\n (1751, 1),\n (1758, 0),\n (1764, 1),\n (1765, 0),\n (1777, 1),\n (1778, 1),\n (1781, 1),\n (1782, 1),\n (1783, 1),\n (1785, 0),\n (1788, 1),\n (1793, 1),\n (1794, 1),\n (1795, 1),\n (1797, 1),\n (1800, 1),\n (1801, 1),\n (1805, 1),\n (1806, 1),\n (1819, 1),\n (1820, 1),\n (1825, 1),\n (1828, 0),\n (1829, 0),\n (1830, 1),\n (1839, 1),\n (1843, 0),\n (1844, 0),\n (1846, 0),\n (1849, 0),\n (1850, 0),\n (1854, 0),\n (1855, 0),\n (1858, 0),\n (1859, 0),\n (1862, 0),\n (1867, 0),\n (1868, 0),\n (1871, 1),\n (1872, 0),\n (1874, 1),\n (1876, 0),\n (1879, 0),\n (1884, 1),\n (1891, 0),\n (1894, 0),\n (1896, 1),\n (1902, 0),\n (1903, 0),\n (1904, 0),\n (1906, 1),\n (1907, 0),\n (1912, 0),\n (1913, 0),\n (1923, 1),\n (1926, 1),\n (1928, 0),\n (1930, 1),\n (1931, 0),\n (1934, 0),\n (1936, 1),\n (1944, 1),\n (1946, 0),\n (1947, 0),\n (1958, 1),\n (1964, 0),\n (1970, 1),\n (1974, 0),\n (1977, 1),\n (1978, 1),\n (1982, 1),\n (1984, 1),\n (1988, 1),\n (1993, 1),\n (1997, 1),\n (1998, 1),\n (2002, 0),\n (2004, 1),\n (2005, 1),\n (2008, 1),\n (2011, 1),\n (2013, 0),\n (2018, 1),\n (2021, 1),\n (2025, 0),\n (2029, 1),\n (2030, 1),\n (2032, 0),\n (2037, 1),\n (2041, 1),\n (2044, 1),\n (2048, 1),\n (2052, 1),\n (2053, 1),\n (2054, 1),\n (2062, 0),\n (2065, 0),\n (2066, 0),\n (2072, 1),\n (2079, 0),\n (2080, 0),\n (2085, 0),\n (2088, 1),\n (2090, 0),\n (2092, 1),\n (2093, 0),\n (2101, 0),\n (2104, 0),\n (2105, 1),\n (2106, 0),\n (2107, 0),\n (2120, 0),\n (2124, 0),\n (2127, 0),\n (2130, 0),\n (2132, 0),\n (2135, 0),\n (2137, 1),\n (2140, 0),\n (2143, 1),\n (2147, 0),\n (2151, 0),\n (2152, 1),\n (2155, 0),\n (2156, 0),\n (2162, 0),\n (2165, 1),\n (2166, 1),\n (2167, 0),\n (2168, 0),\n (2170, 0),\n (2178, 1),\n (2180, 1),\n (2182, 0),\n (2184, 0),\n (2185, 1),\n (2187, 0),\n (2196, 0),\n (2197, 1),\n (2199, 0),\n (2200, 0),\n (2201, 0),\n (2202, 0),\n (2206, 0),\n (2208, 1),\n (2218, 0),\n (2223, 1),\n (2224, 1),\n (2226, 0),\n (2228, 1),\n (2232, 1),\n (2234, 1),\n (2243, 1),\n (2247, 0),\n (2249, 1),\n (2252, 1),\n (2253, 1),\n (2259, 0),\n (2261, 0),\n (2264, 0),\n (2268, 0),\n (2269, 0),\n (2270, 0),\n (2276, 1),\n (2283, 0),\n (2287, 1),\n (2290, 0),\n (2291, 0),\n (2293, 0),\n (2295, 0),\n (2302, 0),\n (2305, 1),\n (2310, 1),\n (2313, 0),\n (2316, 1),\n (2320, 0),\n (2322, 1),\n (2323, 1),\n (2326, 0),\n (2328, 1),\n (2331, 0),\n (2335, 1),\n (2338, 1),\n (2343, 1),\n (2344, 0),\n (2345, 0),\n (2353, 1),\n (2355, 0),\n (2357, 0),\n (2360, 1),\n (2365, 0),\n (2369, 1),\n (2371, 1),\n (2378, 0),\n (2380, 1),\n (2381, 0),\n (2383, 1),\n (2384, 0),\n (2392, 0),\n (2393, 0),\n (2401, 1),\n (2403, 0),\n (2404, 0),\n (2405, 0),\n (2407, 0),\n (2411, 0),\n (2424, 0),\n (2426, 0),\n (2431, 0),\n (2433, 0),\n (2434, 0),\n (2436, 0),\n (2439, 0),\n (2444, 0),\n (2447, 0),\n (2448, 0),\n (2449, 0),\n (2450, 0),\n (2461, 1),\n (2469, 0),\n (2472, 0),\n (2473, 0),\n (2474, 0),\n (2477, 0),\n (2481, 1),\n (2484, 0),\n (2495, 0),\n (2503, 0),\n (2509, 1),\n (2511, 1),\n (2518, 1),\n (2522, 1),\n (2525, 1),\n (2526, 1),\n (2529, 1),\n (2533, 1),\n (2549, 0),\n (2551, 0),\n (2558, 1),\n (2562, 1),\n (2563, 1),\n (2567, 0),\n (2574, 0),\n (2577, 1),\n (2578, 0),\n (2580, 0),\n (2581, 0),\n (2583, 1),\n (2584, 0),\n (2586, 1),\n (2589, 1),\n (2595, 0),\n (2596, 1),\n (2600, 1),\n (2601, 1),\n (2607, 1),\n (2610, 0),\n (2613, 0),\n (2615, 0),\n (2618, 1),\n (2620, 0),\n (2623, 1),\n (2626, 0),\n (2630, 1),\n (2634, 1),\n (2636, 1),\n (2638, 1),\n (2639, 1),\n (2646, 0),\n (2650, 1),\n (2652, 1),\n (2653, 0),\n (2654, 0),\n (2662, 0),\n (2665, 0),\n (2669, 0),\n (2674, 0),\n (2678, 0),\n (2681, 0),\n (2685, 0),\n (2686, 0),\n (2690, 0),\n (2697, 0),\n (2699, 0),\n (2704, 0),\n (2705, 0),\n (2710, 0),\n (2712, 0),\n (2713, 0),\n (2716, 0),\n (2717, 0),\n (2718, 0),\n (2721, 0),\n (2722, 0),\n (2735, 0),\n (2737, 0),\n (2738, 0),\n (2742, 0),\n (2745, 0),\n (2746, 0),\n (2747, 0),\n (2750, 0),\n (2751, 0),\n (2754, 0),\n (2762, 1),\n (2764, 0),\n (2772, 0),\n (2775, 0),\n (2776, 0),\n (2779, 0),\n (2781, 0),\n (2789, 0),\n (2790, 0),\n (2791, 0),\n (2798, 0),\n (2800, 0),\n (2804, 1),\n (2805, 0),\n (2806, 0),\n (2809, 1),\n (2810, 1),\n (2812, 0),\n (2814, 1),\n (2816, 1),\n (2818, 1),\n (2823, 0),\n (2824, 1),\n (2834, 1),\n (2837, 0),\n (2840, 1),\n (2845, 1),\n (2847, 1),\n (2848, 0),\n (2850, 1),\n (2859, 0),\n (2862, 0),\n (2868, 1),\n (2874, 1),\n (2876, 0),\n (2892, 0),\n (2894, 1),\n (2897, 0),\n (2901, 0),\n (2903, 0),\n (2904, 0),\n (2906, 0),\n (2914, 0),\n (2918, 0),\n (2919, 0),\n (2923, 0),\n (2926, 0),\n (2928, 0),\n (2930, 0),\n (2938, 0),\n (2940, 1),\n (2949, 0),\n (2951, 0),\n (2958, 0),\n (2961, 0),\n (2962, 0),\n (2964, 0),\n (2966, 0),\n (2967, 0),\n (2968, 0),\n (2972, 0),\n (2977, 0),\n (2978, 0),\n (2979, 0),\n (2981, 0),\n (2985, 0),\n (2986, 0),\n (2989, 1),\n (2994, 0),\n (2996, 1),\n (2997, 0),\n (2999, 0),\n (3002, 0),\n (3007, 0),\n (3008, 0),\n (3017, 0),\n (3020, 0),\n (3024, 0),\n (3028, 1),\n (3031, 1),\n (3032, 0),\n (3033, 1),\n (3035, 0),\n (3040, 1),\n (3041, 0),\n (3046, 0),\n (3050, 0),\n (3063, 0),\n (3065, 1),\n (3067, 1),\n (3069, 0),\n (3076, 1),\n (3078, 1),\n (3081, 0),\n (3087, 1),\n (3088, 1),\n (3094, 0),\n (3096, 1),\n (3098, 1),\n (3103, 1),\n (3110, 1),\n (3113, 1),\n (3121, 1),\n (3127, 1),\n (3128, 1),\n (3129, 1),\n (3135, 1),\n (3143, 1),\n (3146, 1),\n (3148, 1),\n (3149, 1),\n (3151, 1),\n (3156, 0),\n (3160, 0),\n (3164, 0),\n (3169, 0),\n (3178, 0),\n (3187, 0),\n (3194, 0),\n (3202, 0),\n (3203, 0),\n (3204, 0),\n (3206, 1),\n (3207, 0),\n (3208, 0),\n (3209, 1),\n (3213, 0),\n (3214, 0),\n (3215, 0),\n (3220, 0),\n (3223, 0),\n (3224, 0),\n (3226, 0),\n (3228, 0),\n (3230, 0),\n (3232, 0),\n (3233, 0),\n (3234, 0),\n (3238, 0),\n (3246, 0),\n (3247, 1),\n (3250, 1),\n (3251, 0),\n (3254, 0),\n (3257, 1),\n (3258, 0),\n (3261, 1),\n (3267, 0),\n (3268, 0),\n (3269, 0),\n (3271, 0),\n (3272, 0),\n (3273, 0),\n (3279, 0),\n (3290, 0),\n (3291, 0),\n (3293, 0),\n (3294, 1),\n (3298, 0),\n ...]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = predict(model_, test_texts)\n",
    "ans"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "with open(\"Data/nlp-getting-started/results.txt\", 'w') as file:\n",
    "    file.write(\"id,target\")\n",
    "    for id, y in ans:\n",
    "        file.write(str(id) + \",\" + str(y) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:56<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.02716784151636159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.024040912460552764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.023923481996309358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.022906982383509394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0228723414319139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:57<00:00,  8.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.022353497110365352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.021474640125155535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.020708145139887158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.020356172990078126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0197650981998624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:01<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.019511855635435334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:02<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.019006742909054776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01859222596948216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.018135466071914182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.017491735898537236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tune(model_, optim, train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:58<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.013112363197025934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:03<00:00,  7.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01332581408798085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:01<00:00,  7.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01353422429685709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:00<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.014430892224587362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:00<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.014471119309230538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:00<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01335484397944457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:00<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.012455896564041464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:01<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.01225980437187706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:03<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.012336094889556958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [01:01<00:00,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.012206876997326633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tune(model_, optim, train, epochs=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [00:21<00:00, 152.24it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ans = predict(model_, test_texts)\n",
    "with open(\"Data/nlp-getting-started/results.txt\", 'w') as file:\n",
    "    file.write(\"id,target\")\n",
    "    for id, y in ans:\n",
    "        file.write(str(id) + \",\" + str(y) + \"\\n\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "with open(\"Data/nlp-getting-started/results.txt\", 'w') as file:\n",
    "    file.write(\"id,target\")\n",
    "    for id, y in ans:\n",
    "        file.write(str(id) + \",\" + str(y) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}